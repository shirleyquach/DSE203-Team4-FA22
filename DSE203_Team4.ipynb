{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/lib/python3/dist-packages/html5lib/_trie/_base.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import difflib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
    "import spacy\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim\n",
    "import nltk\n",
    "import py_stringmatching as sm \n",
    "from py_stringmatching.similarity_measure import cosine as cos\n",
    "import pyLDAvis\n",
    "%matplotlib inline\n",
    "\n",
    "import wikipedia\n",
    "import wikipediaapi\n",
    "from unidecode import unidecode\n",
    "\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "#-------\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_profile(files):\n",
    "\n",
    "    # a function to read profile data from profile_files (brand and user)\n",
    "\n",
    "    \"\"\"\n",
    "    [Name]   [Followers]   [Followees]   [Posts]   [URL]   [T/F (you can ignore this field ]   [Category]   [Bio]   [E-mail]   [Phone]   [Profile_pic]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    profile_df = []\n",
    "\n",
    "    #itarate through the profile files\n",
    "    for file in files:\n",
    "\n",
    "        try:\n",
    "\n",
    "\n",
    "            head, username = os.path.split(file)  #get the filename /username  (teh file name is the username )\n",
    "            #use pandas to read the file , map each field to its respective headers for eg: col1  represent teh field Name\n",
    "            prof_info = pd.read_csv(file,delimiter='\\t', usecols=[0,1,2,3,4,5,6,7,8,9,10], names=['Name', 'Followers',\"Followees\",'Posts','URL','T/F','Category','Bio','E-mail','Phone','Profile_pic'], header=None)\n",
    "            prof_info['username'] = username #add the username to the dataframe\n",
    "            profile_df.append(prof_info) # save the frame into a list\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return pd.concat(profile_df) #concat all the Dataframes and return a single Dataframe with all the profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process__User_nodes(node):\n",
    "\n",
    "    #helper function to extract usernames from  edge_media_to_tagged_user & edge_media_to_sponsor_user nodes\n",
    "    #\n",
    "\n",
    "    res = []\n",
    "    try:\n",
    "\n",
    "        for edge in node['edges']:\n",
    "\n",
    "            try:\n",
    "                res.append(edge[\"node\"][\"user\"][\"username\"])\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return \",\".join(res)\n",
    "\n",
    "\n",
    "def get_caption(node):\n",
    "\n",
    "    #helper function to get the caption text\n",
    "    res = []\n",
    "    try:\n",
    "        for edge in node['edges']:\n",
    "            try:\n",
    "                res.append(edge[\"node\"][\"text\"])\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return \",\".join(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json(data):\n",
    "    \"\"\"\n",
    "\n",
    "    a function to process the raw json data and normalize the data\n",
    "\n",
    "\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['edge_media_to_tagged_user'] = process__User_nodes(data.get('edge_media_to_tagged_user',{})) # get a comma separated list of all tagged users\n",
    "    dataset['edge_media_to_sponsor_user'] = process__User_nodes(data.get('edge_media_to_sponsor_user',{})) # get a comma separated list of all sponserd users\n",
    "    dataset['edge_media_to_caption'] = get_caption(data.get('edge_media_to_caption',{})) # get the post caption text\n",
    "    dataset['owner_full_name'] = data.get('owner',{}).get(\"full_name\",None) # get post owners  full name if avilable, Defaults to None\n",
    "    dataset['owner_username'] = data.get('owner',{}).get(\"username\",None) # get post owners  username if avilable, Defaults to None\n",
    "    dataset['owner_id'] = data.get('owner',{}).get(\"id\",None) # get post owners id if avilable, Defaults to None\n",
    "    dataset['edge_media_preview_like'] = data.get('edge_media_preview_like',{}).get(\"count\",None)  # get total likes on the post if avilable, Defaults to None\n",
    "    dataset['edge_media_to_comment'] = data.get('edge_media_to_comment',{}).get(\"count\",None) # get the total comment count if avilable, Defaults to None\n",
    "    dataset[\"Id\"] = data.get(\"id\",None) # get the post id if avilable, Defaults to None\n",
    "    dataset[\"Is_ad\"] = data.get(\"is_ad\",False)  # get the is_ad value  if avilable, Defaults to False\n",
    "    dataset[\"Is_video\"] = data.get(\"is_video\",False)  # get the is_video value if avilable, Defaults to False\n",
    "    dataset[\"Location\"] = data.get(\"location\",None)  # get the location data if avilable, Defaults to None\n",
    "    dataset[\"json_file\"] = data.get(\"id\",\"\")+'.json'  # get the json_file name json_file = [postid].json\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def process_post(chunk):\n",
    "    \"\"\"\n",
    "\n",
    "    function to process the post.json files\n",
    "    a list of postid.json file path is given as input\n",
    "\n",
    "\n",
    "    :param chunk:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    #itarate through each postid.json file\n",
    "    for post_file in chunk:\n",
    "\n",
    "        post_data = json.loads(open(post_file,'r',encoding='utf-8-sig').read()) #read the json file into post_data variable\n",
    "        try:\n",
    "            yield process_json(post_data)\n",
    "            # use process_json function to process the raw json data and yield the result from here\n",
    "            # a genrater is used here becouse we dont want to keep the large data dict in memmory\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        post_data = None #memmory optimization\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting profile and brand files to csv files  for faster read - you only need to run this one time\n",
    "once you have th file in you directory  you may not need to run this  again -> uncomment the block bellow to run it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the files in the users_brands_SPOD and users_influencers_SPOD folders\n",
    "#read_profile function appends all the data and returns a Dataframe\n",
    "\n",
    "profile_brands = read_profile(glob.glob('users_brands_SPOD//*')) # get\n",
    "profile_influencers = read_profile(glob.glob('users_influencers_SPOD//*'))\n",
    "\n",
    "#save the processed data to csv files for simplicity and time management\n",
    "# read_profile is a heavey opration and must be avoided whenever we can\n",
    "profile_brands.to_csv('profile_brands.csv',index=False)\n",
    "profile_influencers.to_csv('profile_influencers.csv',index=False)\n",
    "\n",
    "# you should keep this block commented out once you have full data in the csv file\n",
    "# this block should only be uncommented if you have new profile data to add  and it should be commented back once you have the new csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_brands = pd.read_csv('profile_brands.csv').add_prefix('Brand_') # load the brands csv file and give the coloumns a 'Brand_' prefix to identify between brand and  influencer profiles\n",
    "profile_brands['Brand_username'] = '@'+profile_brands['Brand_username'].str.lower() #add @ to the username\n",
    "profile_influencers = pd.read_csv('profile_influencers.csv').add_prefix('Influencer_')# load the influencers csv file and give the coloumns a 'Influencer_' prefix to identify between brand and  influencer profiles\n",
    "\n",
    "#brands_to_check = ['amazon','sephora','CALVIN KLEIN','Tiffany & Co.','Bumble']  #list of brand names you want to get query the posts for\n",
    "#brands_to_check = [x.lower() for x in brands_to_check]\n",
    "\n",
    "#brands_with_followers_between = profile_brands[profile_brands['Brand_Followers'].between(1500000,1600000)]\n",
    "#brands_to_check = brands_with_followers_between['Brand_Name'].values.tolist() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_brands.index.name\n",
    "profile_brands.index.name = 'brand_id'\n",
    "profile_brands = profile_brands.reset_index(level=0)\n",
    "profile_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_influencers.index.name\n",
    "profile_influencers.index.name = 'influencer_id'\n",
    "profile_influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_influencers = profile_influencers.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def fuzzy_match(brands_to_check_list,name):\n",
    "    #try:\n",
    "\n",
    "        #name = str(name).lower() # convert the profile name to lowercase so that case sensitivity doesn't impact the matching\n",
    "        #closest_match = difflib.get_close_matches(name, brands_to_check_list, 1, 0.9) # use  difflib to get the closest match  with match score greater than 0.9\n",
    "        #if len(closest_match) == 0:\n",
    "            #return None # return null if no match is found\n",
    "        #else:\n",
    "            #return closest_match[0] #return the first match\n",
    "    #except:\n",
    "        #return None # return null on error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_brands['Brand_Name_matched'] = profile_brands['Brand_Name'].apply(lambda x:  fuzzy_match(brands_to_check,x)) #keep the fuzzymatched  data in the 'Brand_Name_matched' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_brands = profile_brands[profile_brands['Brand_Name_matched'].notnull()] # remove all rows with null values in the 'Brand_Name_matched' columns  so that only the matched values remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_brands = profile_brands[profile_brands['Brand_Followers'].between(1500000,1600000)]\n",
    "profile_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pandas to read the post_info.txt file , map each field to its respective headers for eg: col1  represent the field username\n",
    "post_info = pd.read_csv('post_info.txt',delimiter='\\t', usecols=[1,2,3], names=['username', 'Sponsorship_label',\"json_file\"], header=None)\n",
    "# get all posts by  users specified in the 'usernames_to_check'  list\n",
    "# keep only the posts where 'Sponsorship_label' equals '1'\n",
    "post_info = post_info[(post_info['Sponsorship_label'] == 1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we dont need the above part if we are useing all_sponserd_posts.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read json files from json_file folder\n",
    "#json_files = [f\"json_file//{x.strip()}\" for x in post_info['json_file'].tolist()]\n",
    "\n",
    "#with open('all_sponserd_posts.json','w',encoding='utf-8-sig') as myjsonfile:\n",
    "    #json.dump([x for x in process_post(json_files)],myjsonfile) #merge all the json files into one file for faster acces next time\n",
    "\n",
    "# you should keep this block commented out once you have full data in the json file\n",
    "# this block should only be uncommented if you have new post files to add  and it should be commented back once you have the all_sponserd_posts.json file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_df = pd.DataFrame([x for x in process_post(json_files)]) # process those json files and load it into a dataframe # uncomment this line if you dont want to use all_sponserd_posts.json\n",
    "\n",
    "chunk_df = pd.DataFrame(json.loads(open('all_sponserd_posts.json','r',encoding='utf-8-sig').read()))#use the all_sponserd_posts.json file for faster access\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = chunk_df.merge(post_info,on=\"json_file\",how='left')   # merge the new dataframe with post_info Dataframe based on the \"json_file\" coloumn present in both the dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_usernames_from_tokens(edge_media_to_caption_tokes):\n",
    "\n",
    "    # check if token array is empty or not if empty  return null\n",
    "    if len(edge_media_to_caption_tokes) == 0:\n",
    "        return None\n",
    "\n",
    "\n",
    "    matched_brands = []  #to hold matched brands\n",
    "\n",
    "    #itarate through all the tokens\n",
    "    for token in edge_media_to_caption_tokes:\n",
    "        b = str(token).strip().lower() #convert each token to lowercase and strip whitespaces for a standerdized form\n",
    "        if b.startswith('@'): # if a token starts with \"@\" we can  safely assume its a username\n",
    "            matched_brands.append(token) # add the token to the matched list\n",
    "\n",
    "    if len(matched_brands) == 0:\n",
    "        # there is no matched brands then return None\n",
    "        return None\n",
    "    else:\n",
    "        #remove duplicates and return matched list\n",
    "        return list(set(matched_brands))\n",
    "\n",
    "def tokenize_str(string):\n",
    "    #split string by whitespace remove all special chars Except\n",
    "    string = str(string).lower() # convert the text into lowercase for easier matching\n",
    "    string = string.replace('#',\" #\").replace('\\n',\" \\n\") # replace all \"#\" values with \" #\" (whitespace + #) otherwise this would give a false match\n",
    "    return re.sub(\"[^\\w@ ]\", \"\", string).split()  #split string by whitespace remove all special chars Except @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df['edge_media_to_caption_tokes'] =  chunk_df['edge_media_to_caption'].apply(tokenize_str,lambda x:x)  # tokanize the edge_media_to_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunk_df['brand_matched'] = chunk_df['edge_media_to_caption_tokes'].apply(lambda x:get_all_usernames_from_tokens(x)) # call get_all_usernames_from_tokens function to get all usernames from caption\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df = chunk_df.explode('brand_matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.dropna(subset=['brand_matched'],inplace=True) #remove all rows where brand_matched is null\n",
    "del chunk_df['edge_media_to_caption_tokes'] # delete edge_media_to_caption_tokes - > we dont need this anymore\n",
    "\n",
    "\n",
    "chunk_df = chunk_df[chunk_df['brand_matched'].isin(profile_brands['Brand_username'])] #check if the matched brand is in the brands_to_check list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the new dataframe with profile_brands Dataframe,  keep all records where 'brand_matched' from the new df  equals 'Brand_username' on the profile_brands Dataframe\n",
    "chunk_df = chunk_df.merge(profile_brands,left_on='brand_matched',right_on='Brand_username',how='left')\n",
    "\n",
    "# join the new dataframe with profile_influencers Dataframe,  keep all records where 'username' from the new df  equals 'Influencer_username' on the profile_influencers Dataframe\n",
    "chunk_df = chunk_df.merge(profile_influencers,left_on='username',right_on='Influencer_username',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df # print the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "chunk_df # print the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_df.to_csv('final_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby(['brand_matched']).apply(lambda x: x.nlargest(20,['Influencer_Followers'])).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = g[['brand_id','Brand_Name','Brand_Followers','Brand_Followees','Brand_Posts','Brand_URL','Brand_Category','Id','edge_media_to_caption','edge_media_preview_like','edge_media_to_comment','influencer_id','Influencer_Name','Influencer_Followers','Influencer_Followees','Influencer_Posts','Influencer_Category']]\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final.rename(columns = {'Id':'post_id','edge_media_to_caption':'post_caption', 'edge_media_preview_like':'post_likes','edge_media_to_comment':'post_comments'}, inplace = True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('df_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Brand Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang('en')\n",
    "wikiApi = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern  = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "def remove_emoji(input_string):\n",
    "    for ele in input_string:\n",
    "        word = emoji_pattern.sub(r'', input_string) # No emoji\n",
    "    return word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "<>:3: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\s\n",
      "/tmp/ipykernel_8287/1104507845.py:3: DeprecationWarning: invalid escape sequence \\S\n",
      "  listOfWords = [re.sub('\\S*@\\S*\\s?', '', word).lower() for word in listOfWords]\n",
      "/tmp/ipykernel_8287/1104507845.py:5: DeprecationWarning: invalid escape sequence \\s\n",
      "  listOfWords = [re.sub('\\s+', ' ', word) for word in listOfWords]\n"
     ]
    }
   ],
   "source": [
    "def cleanListOfWords(listOfWords):\n",
    "    listOfWords =  [remove_emoji(i).lower() for i in listOfWords if i != '']\n",
    "    listOfWords = [re.sub('\\S*@\\S*\\s?', '', word).lower() for word in listOfWords]\n",
    "    listOfWords = [re.sub(r\"[^a-zA-Z0-9 ]\", \" \", word) for word in listOfWords]\n",
    "    listOfWords = [re.sub('\\s+', ' ', word) for word in listOfWords]\n",
    "    listOfWords = [re.sub(\"\\'\", \"\", word) for word in listOfWords]\n",
    "    listOfWords = [re.sub(r'[^\\w\\s]', '', word) for word in listOfWords]\n",
    "    listOfWords = [unidecode(word) for word in listOfWords]\n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nike Training Club Live',\n",
       " 'Gymshark Women',\n",
       " 'Pizza Hut üçï',\n",
       " 'Massimo Dutti',\n",
       " 'hotmiamistyles',\n",
       " 'Philadelphia Eagles',\n",
       " 'Rogue Fitness',\n",
       " 'QUAY AUSTRALIA',\n",
       " 'Barneys New York',\n",
       " 'Bottega Veneta',\n",
       " 'RubyRose_Oficial',\n",
       " 'ROXY',\n",
       " 'TEZENiS',\n",
       " 'adidas London',\n",
       " 'Amazon',\n",
       " 'Rashida Jones',\n",
       " 'Official Kylie Jenner Shop',\n",
       " 'Burger King',\n",
       " 'Glossier',\n",
       " 'Ludovica Valli',\n",
       " 'Koton',\n",
       " 'live lokai',\n",
       " 'CREME PARA ESTRIAS',\n",
       " 'Bergdorf Goodman',\n",
       " 'FARS√ÅLI - Beauty with Benefits',\n",
       " 'CELINE',\n",
       " 'McClure Twins - Ava and Alexis',\n",
       " 'Universal Studios Hollywood',\n",
       " 'Universal Orlando Resort',\n",
       " 'Moda',\n",
       " 'dm-drogerie markt Deutschland',\n",
       " 'The Body Shop Official',\n",
       " 'Wish',\n",
       " 'Shawn Johnson East',\n",
       " 'OnePlus']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brandNames = list(set(df_final[\"Brand_Name\"]))\n",
    "brandNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nike training club live',\n",
       " 'gymshark women',\n",
       " 'pizza hut ',\n",
       " 'massimo dutti',\n",
       " 'hotmiamistyles',\n",
       " 'philadelphia eagles',\n",
       " 'rogue fitness',\n",
       " 'quay australia',\n",
       " 'barneys new york',\n",
       " 'bottega veneta',\n",
       " 'rubyrose oficial',\n",
       " 'roxy',\n",
       " 'tezenis',\n",
       " 'adidas london',\n",
       " 'amazon',\n",
       " 'rashida jones',\n",
       " 'official kylie jenner shop',\n",
       " 'burger king',\n",
       " 'glossier',\n",
       " 'ludovica valli',\n",
       " 'koton',\n",
       " 'live lokai',\n",
       " 'creme para estrias',\n",
       " 'bergdorf goodman',\n",
       " 'fars li beauty with benefits',\n",
       " 'celine',\n",
       " 'mcclure twins ava and alexis',\n",
       " 'universal studios hollywood',\n",
       " 'universal orlando resort',\n",
       " 'moda',\n",
       " 'dm drogerie markt deutschland',\n",
       " 'the body shop official',\n",
       " 'wish',\n",
       " 'shawn johnson east',\n",
       " 'oneplus']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedBrandNames = cleanListOfWords(brandNames)\n",
    "cleanedBrandNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_token = sm.QgramTokenizer(qval=3)\n",
    "cosine = cos.Cosine()\n",
    "jaccard = sm.Jaccard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phrasesList = []\n",
    "for (idx, brand) in enumerate(cleanedBrandNames):\n",
    "    #get rid of all unecessary words that could skew cosine similarity\n",
    "    plainBrandName = brandNames[idx]\n",
    "    phrase = '%20'.join([remove_stopwords(abst) for abst in brand.split(' ')])\n",
    "    url = f'https://en.wikipedia.org/w/api.php?action=query&list=search&srsearch={phrase}&utf8=&format=json'\n",
    "    jsonPhrase = pd.read_json(url, orient='records')\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for brandToToken in [brand + '(company)']:\n",
    "        phraseToken = q3_token.tokenize(brandToToken)\n",
    "        for result in jsonPhrase['query']['search']:            \n",
    "            title = result['title'].lower()           \n",
    "            q3TokenSample = q3_token.tokenize(title)\n",
    "            cosScoreQ3 = cosine.get_sim_score(q3TokenSample, phraseToken)\n",
    "            scores.append([result['title'], cosScoreQ3]) \n",
    "        \n",
    "    if('roxy' in brand):\n",
    "        scores = [[\"Quicksilver (company)\", 1]]\n",
    "    if('moda' == brand):\n",
    "        scores = [[\"Mod√†\", 1.1]]\n",
    "\n",
    "    if(scores):\n",
    "        maxScore = max(scores, key=lambda item:item[1])\n",
    "        phrasesList.append([plainBrandName, maxScore[0]])    \n",
    "    else:\n",
    "        phrasesList.append([plainBrandName, ''])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Nike Training Club Live', 'Nike, Inc.'],\n",
       " ['Gymshark Women', 'Gymshark'],\n",
       " ['Pizza Hut üçï', 'Pizza Hut'],\n",
       " ['Massimo Dutti', 'Massimo Dutti'],\n",
       " ['hotmiamistyles', ''],\n",
       " ['Philadelphia Eagles', 'Philadelphia Eagles'],\n",
       " ['Rogue Fitness', 'Rogue Fitness'],\n",
       " ['QUAY AUSTRALIA', 'Quay (restaurant)'],\n",
       " ['Barneys New York', 'Barneys New York'],\n",
       " ['Bottega Veneta', 'Bottega Veneta'],\n",
       " ['RubyRose_Oficial', ''],\n",
       " ['ROXY', 'Quicksilver (company)'],\n",
       " ['TEZENiS', 'Sandro Veronesi (entrepreneur)'],\n",
       " ['adidas London', 'Adidas'],\n",
       " ['Amazon', 'Amazon (company)'],\n",
       " ['Rashida Jones', 'Rashida Jones'],\n",
       " ['Official Kylie Jenner Shop', 'Kendall Jenner'],\n",
       " ['Burger King', 'Burger King'],\n",
       " ['Glossier', 'Glossy ibis'],\n",
       " ['Ludovica Valli', 'Ludovica Torelli'],\n",
       " ['Koton', 'Koton (company)'],\n",
       " ['live lokai', 'List of Tales from the Crypt episodes'],\n",
       " ['CREME PARA ESTRIAS', ''],\n",
       " ['Bergdorf Goodman', 'Bergdorf Goodman'],\n",
       " ['FARS√ÅLI - Beauty with Benefits', 'Li Yundi'],\n",
       " ['CELINE', 'Celine (brand)'],\n",
       " ['McClure Twins - Ava and Alexis', 'McClure twins'],\n",
       " ['Universal Studios Hollywood', 'Universal Studios Hollywood'],\n",
       " ['Universal Orlando Resort', 'Universal Orlando'],\n",
       " ['Moda', 'Mod√†'],\n",
       " ['dm-drogerie markt Deutschland', 'EBS Symposium'],\n",
       " ['The Body Shop Official', 'The Body Shop'],\n",
       " ['Wish', 'Wish (company)'],\n",
       " ['Shawn Johnson East', 'Shawn Johnson East'],\n",
       " ['OnePlus', 'OnePlus']]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrasesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, nlp, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKeywords(brandName, listOfWords, numWords):\n",
    "    wikiPage = cleanListOfWords(listOfWords)\n",
    "    wikiPage = [word for word in wikiPage if word.lower() not in brandName.lower().split(\" \")]\n",
    "    \n",
    "    absGram = [remove_stopwords(abst) for abst in wikiPage]\n",
    "    absGramSplit = [remove_stopwords(abst).split(' ') for abst in wikiPage]\n",
    "    \n",
    "    bigram = gensim.models.Phrases(absGramSplit, min_count=4, threshold=1000) \n",
    "    trigram = gensim.models.Phrases(bigram[absGramSplit], threshold=100)  \n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "    def make_bigrams(texts):\n",
    "        return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "    def make_trigrams(texts):\n",
    "        return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "    data_words_trigrams = make_trigrams(absGramSplit)\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "    tri_lemmatized = lemmatization(data_words_trigrams, nlp, allowed_postags=['NOUN', 'ADJ', 'VERB'])\n",
    "\n",
    "    id2word = corpora.Dictionary(tri_lemmatized)\n",
    "    texts = tri_lemmatized\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "    allTopics = []\n",
    "    ldaModel = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=numWords, \n",
    "                                           random_state=133,\n",
    "                                           update_every=10,\n",
    "                                           chunksize=len(wikiPage),\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)           \n",
    "\n",
    "    doc_lda = ldaModel[corpus]\n",
    "\n",
    "    topics = []\n",
    "    \n",
    "    for idx, topic in ldaModel.show_topics(formatted=False, num_words= numWords):\n",
    "        topics.extend([w[0] for w in topic])\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kateolaughlin/.local/lib/python3.8/site-packages/spacy/language.py:1895: UserWarning: [W123] Argument disable with value ['parser', 'ner'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Nike Training Club Live', ['brand', 'air', 'company', 'equipment']], ['Gymshark Women', ['retailer', 'retail', 'fitness', 'company']], ['Pizza Hut üçï', ['serve', 'location', 'chain', 'large']], ['Massimo Dutti', ['multinational', 'luxury', 'pronunciation', 'spanish']], ['hotmiamistyles', []], ['Philadelphia Eagles', ['football', 'appear', 'team', 'rivalry']], ['Rogue Fitness', ['gym', 'base', 'equipment', 'box']], ['QUAY AUSTRALIA', ['award', 'run', 'appear', 'restaurant']], ['Barneys New York', ['brand', 'avenue', 'authentic', 'fifth']], ['Bottega Veneta', ['branding', 'license', 'accessory', 'jewelry']], ['RubyRose_Oficial', []], ['ROXY', ['quicksilver', 'gambling', 'amusement', 'machine']], ['TEZENiS', ['net', 'sandro', 'worth', 'veronesi']], ['adidas London', ['large', 'shoe', 'dassler', 'spike']], ['Amazon', ['stream', 'refer', 'online', 'large']], ['Rashida Jones', ['series', 'hot', 'comedy', 'film']], ['Official Kylie Jenner Shop', ['list', 'fame', 'model', 'campaign']], ['Burger King', ['orient', 'acquire', 'cp', 'set']], ['Glossier', ['refer', 'ancient', 'sickle', 'mean']], ['Ludovica Valli', ['countess', 'instrumental', 'institutes', 'ruling']], ['Koton', ['store', 'retail', 'multinational', 'turkish']], ['live lokai', ['total', 'episode', 'television', 'series']], ['CREME PARA ESTRIAS', []], ['Bergdorf Goodman', ['avenue', 'store', 'fifth', 'locate']], ['FARS√ÅLI - Beauty with Benefits', ['competition', 'chinese', 'young', 'know']], ['CELINE', ['line', 'french', 'officer', 'luxury']], ['McClure Twins - Ava and Alexis', ['know', 'young', 'twin', 'viral']], ['Universal Studios Hollywood', ['park', 'offer', 'theme', 'city']], ['Universal Orlando Resort', ['loew', 'royal', 'hotel', 'world']], ['Moda', ['silvestre', 'bass', 'guitarist', 'pop']], ['dm-drogerie markt Deutschland', ['year', 'speaker', 'symposium', 'eb']], ['The Body Shop Official', ['natura', 'cosmetic', 'trading', 'sell']], ['Wish', ['buyer', 'seller', 'platform', 'payment']], ['Shawn Johnson East', ['champion', 'world', 'team', 'balance']], ['OnePlus', ['manufacturer', 'electronic', 'pei', 'consumer']]]\n"
     ]
    }
   ],
   "source": [
    "keyWordsList = []\n",
    "for brand in phrasesList:\n",
    "    topicsOfTopics = []\n",
    "    if(brand[1] != ''):\n",
    "        wikiTitle = brand[1]\n",
    "        wikiPage = wikipedia.summary(title = wikiTitle, auto_suggest=False).split(' ')\n",
    "        topics = findKeywords(brand[0], wikiPage, 10);\n",
    "        topicsOfTopics = findKeywords(brand[0], topics, 2)\n",
    "    \n",
    "    keyWordsList.append([brand[0], topicsOfTopics])\n",
    "    \n",
    "print(keyWordsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Nodes and Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Brand Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "for word in keyWordsList:\n",
    "    brand = df_final[df_final['Brand_Name'] == word[0]].iloc[0]\n",
    "    nodes.append([brand['brand_id'], \"Brand\", brand['Brand_Name'], word[1], brand['Brand_Followers'], \\\n",
    "                  brand['Brand_Followees'], brand['Brand_Posts'], brand[\"Brand_URL\"], brand[\"Brand_Category\"]])\n",
    "        \n",
    "brandNodeDf = pd.DataFrame(nodes, columns=['brand_ID', ':LABEL','Brand_Name','Keywords', \"Number_Of_Followers\", \"Number_Of_Followees\", \"Number_Of_Posts\", \"Brand_Url\", \"Categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_ID</th>\n",
       "      <th>:LABEL</th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Number_Of_Followers</th>\n",
       "      <th>Number_Of_Followees</th>\n",
       "      <th>Number_Of_Posts</th>\n",
       "      <th>Brand_Url</th>\n",
       "      <th>Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19343</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Nike Training Club Live</td>\n",
       "      <td>[brand, air, company, equipment]</td>\n",
       "      <td>1570912.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>https://swoo.sh/2K7uhZs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16013</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Gymshark Women</td>\n",
       "      <td>[retailer, retail, fitness, company]</td>\n",
       "      <td>1503127.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>http://gym.sh/AllYouNeedToKnowToronto</td>\n",
       "      <td>Personal Goods &amp; General Merchandise Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8209</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Pizza Hut üçï</td>\n",
       "      <td>[serve, location, chain, large]</td>\n",
       "      <td>1510972.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>http://www.PizzaHut.com/NFL</td>\n",
       "      <td>Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24856</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Massimo Dutti</td>\n",
       "      <td>[multinational, luxury, pronunciation, spanish]</td>\n",
       "      <td>1576480.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>http://mdutti.me/NorthWinds</td>\n",
       "      <td>Personal Goods &amp; General Merchandise Stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2836</td>\n",
       "      <td>Brand</td>\n",
       "      <td>hotmiamistyles</td>\n",
       "      <td>[]</td>\n",
       "      <td>1597934.0</td>\n",
       "      <td>1059.0</td>\n",
       "      <td>10842.0</td>\n",
       "      <td>http://www.HotMiamiStyles.com/</td>\n",
       "      <td>Personal Goods &amp; General Merchandise Stores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_ID :LABEL               Brand_Name  \\\n",
       "0     19343  Brand  Nike Training Club Live   \n",
       "1     16013  Brand           Gymshark Women   \n",
       "2      8209  Brand              Pizza Hut üçï   \n",
       "3     24856  Brand            Massimo Dutti   \n",
       "4      2836  Brand           hotmiamistyles   \n",
       "\n",
       "                                          Keywords  Number_Of_Followers  \\\n",
       "0                 [brand, air, company, equipment]            1570912.0   \n",
       "1             [retailer, retail, fitness, company]            1503127.0   \n",
       "2                  [serve, location, chain, large]            1510972.0   \n",
       "3  [multinational, luxury, pronunciation, spanish]            1576480.0   \n",
       "4                                               []            1597934.0   \n",
       "\n",
       "   Number_Of_Followees  Number_Of_Posts  \\\n",
       "0                166.0            317.0   \n",
       "1                 47.0           1917.0   \n",
       "2                371.0           1444.0   \n",
       "3                323.0           3002.0   \n",
       "4               1059.0          10842.0   \n",
       "\n",
       "                               Brand_Url  \\\n",
       "0                https://swoo.sh/2K7uhZs   \n",
       "1  http://gym.sh/AllYouNeedToKnowToronto   \n",
       "2            http://www.PizzaHut.com/NFL   \n",
       "3            http://mdutti.me/NorthWinds   \n",
       "4         http://www.HotMiamiStyles.com/   \n",
       "\n",
       "                                    Categories  \n",
       "0                                          NaN  \n",
       "1  Personal Goods & General Merchandise Stores  \n",
       "2                                  Restaurants  \n",
       "3  Personal Goods & General Merchandise Stores  \n",
       "4  Personal Goods & General Merchandise Stores  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brandNodeDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Post Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Number_of_Likes</th>\n",
       "      <th>Number_of_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1877001634463122445</td>\n",
       "      <td>Post</td>\n",
       "      <td>Eu e meu chamego de sempre passando pelo seu f...</td>\n",
       "      <td>46572</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1891646163346665904</td>\n",
       "      <td>Post</td>\n",
       "      <td>Minha cara quando falam: \"Lore, tem sobremesa\"...</td>\n",
       "      <td>54989</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916289352699275991</td>\n",
       "      <td>Post</td>\n",
       "      <td>T√¥ de olho em voc√™ que ainda n√£o seguiu minha ...</td>\n",
       "      <td>67286</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1936582221779537401</td>\n",
       "      <td>Post</td>\n",
       "      <td>Pq se nao tiver essa cara voc√™s sabem que n√£o ...</td>\n",
       "      <td>61472</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961799656992243034</td>\n",
       "      <td>Post</td>\n",
       "      <td>Minha cara para quem fala que ainda n√£o compro...</td>\n",
       "      <td>38757</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               post_ID LABEL  \\\n",
       "0  1877001634463122445  Post   \n",
       "1  1891646163346665904  Post   \n",
       "2  1916289352699275991  Post   \n",
       "3  1936582221779537401  Post   \n",
       "4  1961799656992243034  Post   \n",
       "\n",
       "                                             Caption  Number_of_Likes  \\\n",
       "0  Eu e meu chamego de sempre passando pelo seu f...            46572   \n",
       "1  Minha cara quando falam: \"Lore, tem sobremesa\"...            54989   \n",
       "2  T√¥ de olho em voc√™ que ainda n√£o seguiu minha ...            67286   \n",
       "3  Pq se nao tiver essa cara voc√™s sabem que n√£o ...            61472   \n",
       "4  Minha cara para quem fala que ainda n√£o compro...            38757   \n",
       "\n",
       "   Number_of_Comments  \n",
       "0                 236  \n",
       "1                 286  \n",
       "2                 400  \n",
       "3                 370  \n",
       "4                 289  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postNodeList = []\n",
    "influNodeList = []\n",
    "for index, row in df_final.iterrows():\n",
    "    postNodeList.append([row['post_id'], 'Post', row['post_caption'], row['post_likes'], row['post_comments']])\n",
    "    if row['Influencer_Name'] not in [inf[2] for inf in influNodeList]:\n",
    "        influNodeList.append([row['influencer_id'], 'Influencer', row['Influencer_Name'], \\\n",
    "                              row['Influencer_Followers'], row['Influencer_Followees'], row['Influencer_Posts'], row['Influencer_Category']])\n",
    "    \n",
    "postNodesDf = pd.DataFrame(postNodeList, columns=['post_ID', 'LABEL', 'Caption', 'Number_of_Likes', 'Number_of_Comments'])\n",
    "influNodesDf = pd.DataFrame(influNodeList, columns=['influencerID', 'LABEL', 'Influencer_Name', \"Number_Of_Followers\", \"Number_of_Followees\", \\\n",
    "                                                   \"Number_Of_Posts\", \"Influencer_Category\"])\n",
    "postNodesDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influencerID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Influencer_Name</th>\n",
       "      <th>Number_Of_Followers</th>\n",
       "      <th>Number_of_Followees</th>\n",
       "      <th>Number_Of_Posts</th>\n",
       "      <th>Influencer_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378335</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>5074442.0</td>\n",
       "      <td>1966</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51458</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>1782185.0</td>\n",
       "      <td>302</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372578</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>555818.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>Lifestyle Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56832</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>389510.0</td>\n",
       "      <td>750</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4635</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>MORGANA SANTANA</td>\n",
       "      <td>256163.0</td>\n",
       "      <td>509</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   influencerID       LABEL     Influencer_Name  Number_Of_Followers  \\\n",
       "0        378335  Influencer      Lorena Improta            5074442.0   \n",
       "1         51458  Influencer         Gabi Brandt            1782185.0   \n",
       "2        372578  Influencer  CREME PARA ESTRIAS             555818.0   \n",
       "3         56832  Influencer     Priscila Sim√µes             389510.0   \n",
       "4          4635  Influencer     MORGANA SANTANA             256163.0   \n",
       "\n",
       "   Number_of_Followees  Number_Of_Posts     Influencer_Category  \n",
       "0                 1966           5127.0  Creators & Celebrities  \n",
       "1                  302           1803.0  Creators & Celebrities  \n",
       "2                 1951           2045.0      Lifestyle Services  \n",
       "3                  750           1337.0  Creators & Celebrities  \n",
       "4                  509           2029.0  Creators & Celebrities  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influNodesDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand_id                                                             1279\n",
       "Brand_Name                                               Bergdorf Goodman\n",
       "Brand_Followers                                                 1529651.0\n",
       "Brand_Followees                                                     878.0\n",
       "Brand_Posts                                                        7668.0\n",
       "Brand_URL                                     http://like2b.uy/bergdorfs/\n",
       "Brand_Category                Personal Goods & General Merchandise Stores\n",
       "post_id                                               1238009176605342650\n",
       "post_caption            What's better than flowers and Eau de Parfum f...\n",
       "post_likes                                                           1509\n",
       "post_comments                                                          34\n",
       "influencer_id                                                        8176\n",
       "Influencer_Name                                                       NaN\n",
       "Influencer_Followers                                              86964.0\n",
       "Influencer_Followees                                                  482\n",
       "Influencer_Posts                                                    207.0\n",
       "Influencer_Category                                Creators & Celebrities\n",
       "Name: 72, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>post_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3209</td>\n",
       "      <td>SPONSORED</td>\n",
       "      <td>1877001634463122445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3209</td>\n",
       "      <td>SPONSORED</td>\n",
       "      <td>1891646163346665904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3209</td>\n",
       "      <td>SPONSORED</td>\n",
       "      <td>1916289352699275991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3209</td>\n",
       "      <td>SPONSORED</td>\n",
       "      <td>1936582221779537401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3209</td>\n",
       "      <td>SPONSORED</td>\n",
       "      <td>1961799656992243034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_ID       TYPE              post_ID\n",
       "0      3209  SPONSORED  1877001634463122445\n",
       "1      3209  SPONSORED  1891646163346665904\n",
       "2      3209  SPONSORED  1916289352699275991\n",
       "3      3209  SPONSORED  1936582221779537401\n",
       "4      3209  SPONSORED  1961799656992243034"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relbrandtopost = []\n",
    "for index, row in df_final.iterrows():\n",
    "    postId = postNodesDf[(postNodesDf['Caption'] == row['post_caption']) \\\n",
    "                         & (postNodesDf['Number_of_Likes'] == row['post_likes'])]['post_ID'].iloc[0]\n",
    "    brandId = brandNodeDf[brandNodeDf['Brand_Name'] == row['Brand_Name']]['brand_ID'].iloc[0]\n",
    "    relbrandtopost.append([brandId, \"SPONSORED\", postId])\n",
    "edge_brandtopost = pd.DataFrame(relbrandtopost, columns=['brand_ID', 'TYPE', 'post_ID'])\n",
    "edge_brandtopost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influencer_ID</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>post_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378335</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>1877001634463122445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>378335</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>1891646163346665904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378335</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>1916289352699275991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>378335</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>1936582221779537401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378335</td>\n",
       "      <td>POSTED</td>\n",
       "      <td>1961799656992243034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   influencer_ID    TYPE              post_ID\n",
       "0         378335  POSTED  1877001634463122445\n",
       "1         378335  POSTED  1891646163346665904\n",
       "2         378335  POSTED  1916289352699275991\n",
       "3         378335  POSTED  1936582221779537401\n",
       "4         378335  POSTED  1961799656992243034"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relinfltopost = []\n",
    "for index, row in df_final.iterrows():\n",
    "    if(str(row['Influencer_Name']) != 'nan'):\n",
    "        postId = postNodesDf[(postNodesDf['Caption'] == row['post_caption']) \\\n",
    "                             & (postNodesDf['Number_of_Likes'] == row['post_likes'])]['post_ID'].iloc[0]\n",
    "        influId = influNodesDf[influNodesDf['Influencer_Name'] == row['Influencer_Name']]['influencerID'].iloc[0]\n",
    "        relinfltopost.append([influId, \"POSTED\", postId])\n",
    "edge_relinfltopost = pd.DataFrame(relinfltopost, columns=['influencer_ID', 'TYPE', 'post_ID'])\n",
    "edge_relinfltopost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influNodesDf.to_csv(\"InfluencerNodes.csv\", index=False)\n",
    "postNodesDf.to_csv(\"PostNodes.csv\", index=False)\n",
    "brandNodeDf.to_csv(\"BrandNodes.csv\", index=False)\n",
    "edge_relinfltopost.to_csv(\"Edges_Infl.csv\", index=False)\n",
    "edge_brandtopost.to_csv(\"Edges_Brand.csv\", index=False)\n",
    "#relationList.to_csv(\"files/relationList.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#./bin/neo4j-admin import --force --multiline-fields=true --nodes=./import/1_node.csv --relationships=./import/1_rel.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Famous Person Webscrape Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     Lorena Improta\n",
       "1                     Lorena Improta\n",
       "2                     Lorena Improta\n",
       "3                     Lorena Improta\n",
       "4                     Lorena Improta\n",
       "                   ...              \n",
       "437    Tiffany üåπ - Beauty Influencer\n",
       "438                    üå∏ P I N V R üå∏\n",
       "439                        Annie Cho\n",
       "440          Hi y‚Äôall, I‚Äôm Brandy G!\n",
       "441                            Mandy\n",
       "Name: Influencer_Name, Length: 442, dtype: object"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_influencer = df_final[\"Influencer_Name\"]\n",
    "df_influencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer_names = df_influencer.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorena Improta', 'Gabi Brandt', 'CREME PARA ESTRIAS', 'Priscila Sim√µes', 'MORGANA SANTANA', 'F2Freestylers', 'Tom Daley', 'bradleysimmonds', 'TASHA GREEN', 'N S', 'Sophie Hellyer', 'Khlo√©', 'Vanessa Hudgens', 'Priyanka Chopra', 'Adriana Lima', 'Jessica Biel', 'Nia Sioux', 'Russell Wilson', 'Olivia Culpo', 'Dr. Holly Hatcher-Frazier', 'Kaycee Rice', 'Peter McKinnon', 'Sydney Leroux Dwyer', 'sung kang', 'Meghan King Edmonds', 'bri emery / designlovefest', 'Emily Luciano', 'Claire Godard', 'Farrah Davidson', 'KINDNESS ‚Ä¢ BEAUTY ‚Ä¢ LIFESTYLE', 'Franko Dean', 'THANIA | Fashion & Beauty Blog', 'The Perennial Style', 'Victoria Hui', 'Raysa Garcia', 'Mr.kool //Austin ‚Ñ¢', 'TheSequinHanger', 'LaTonya', 'Carolyn', '| San Diego Blogger', 'T‚Ñ¢ ', 'IDM', 'f·é™sh·èÅ·èüu·èí·é•·éæus: #Fashion #Beauty', 'Opal Stewart', 'Alexandre | ÿßŸÑŸÉÿ≥ÿßŸÜÿØÿ±', 'Amlul.com', 'ManhattanGirl', 'Tina Craig', 'THELIMITDOESNOTEXIST', 'yael steren', 'All The Pretty Birds', 'By Sophie and Charlotte ', nan, 'ELLEN COLE', 'SAVAGE IS THE KING ', 'Simone Vianna  Designer', 'Guido Milani', 'David', 'Atticus + Acorn The Hedgehogs', 'CHANTELL DAPAAH BOAMAH ', 'Fashion, Style & Travel', 'KATIE VAN DAALEN WETTERS', 'Kim Kruse', 'Mike Shirdan', 'Nikki', 'ROMANA B√ñHMOV√Å', 'VICTORIA  LACE', \"L√ºrzer's Archive\", 'James Wallington', 'Style Update Blog', 'Natalia Tong', 'C H A R L I E  S C O T T', 'Kim @  Two Kids and a Coupon', 'Styled Muse', 'LILY  Beauty With Lily', 'Tiempo de Publicidad', 'Adam Ginsberg', 'Lauren Dimet Waters ', 'UME-ROMAAN', 'Anna Leena', '       ÿµÿØŸÅŸâ', 'ItsCaradee', 'Natasha', 'Gabor Szakacs', 'TaniaMauritius', 'Fashion  ‚Ä¢ Travel ‚Ä¢ Food ', 'Nastasia', 'Vivian Dambeck', 'Julia Haupt', 'FASHION  TRAVEL  INSPO', 'Sonja | Travelgirl ', 'Marco', 'SIMONA.JULIA ', 'Katharina Bansemer', 'Jorinna', 'Goodness Destiny GlamGeonu ', 'RAINBOW FOODIE', 'Meira Dins ', '·í™ Y ·ëé ·ëé I ', ' ', 'L U I S A  |  FASHIONLOVER', 'NICKI  | Mama & Youtuber 18K', 'Nyma', 'MILLENNIAL MAMA', 'Rosymelina | Vintage', 'Kia Marie ', 'Aeliya Khan ', '', '', 'Katie Jane Hughes', 'Tar Mar', 'SAVANNAH JAYDE ', 'MOLLIE ROSE ', 'creative hustler.', 'Mark Daryl', 'Lumi_Lise (Elise Gill) ', 'Kackie Reviews Beauty', 'haley pierson', 'Traci Fine', 'Tati McQuay', 'Naomi Genes', ' ', 'Womens Fitness', 'Victoria Marks ', 'Kelsi LaKendra', 'Shanda  Rogers', 'BABY KO', 'Ari', '  ', 'Maddalena –ê—Ä–∏–Ω–∞', '~| Selina Kyjara Romney |~', 'I am Hazel Amari ', 'Rocio Laura', 'Sahar Golestani', 'Naya Ibrahim', 'DONI BROWN', 'M E R V E', ' P I N V R ', 'AND THIS IS MY STYLE', 'D i d e m Karatas', 'Travel, Love, Adventure', '  ', 'Leia', 'La Couleur Du Moment', 'Loulou De Saison - Chlo√©', 'Sara Nicole Rossetto', ' HAIRY SPIRIT ', 'Alexandra', 'Federica Busatti Bei', 'Giovanni Ferrer', 'Mathew Fraser', 'Giorgio Merlino', 'Kevin Elezaj', 'Matt McLean', 'Harry Werz', 'Adanna David', 'Emilie D√©tr√©', 'lecoindelodie', 'Matilde Minauro', 'Nic', 'Thomas | WorldSupercars', 'Eleonora Milano', ' ü·¥Ä·¥ú Ä·¥Ä ·¥Ä·¥¢·¥¢·¥ú Ä Ä·¥Ä  ô…™…¢·¥á ü ü…™', 'Luca Rallo', 'Tom Honeyands', 'Golden Tate', '975TheFanatic', 'May I Have That Recipe', 'Confessions Of A Mother Runner', 'Chef Julie Harrington, RD', 'Vocalbeing', 'Scout Masterson', 'Rob Krager', 'Breanna', 'Arlu PerezParra Castro', 'Beau Coffron', 'Sarah Fortune', 'Daniel Kipnis', 'Jesse Lozano', 'CAMILA COELHO', 'iluvsarahii', 'Sofia Richie', 'Chloe Morello', 'S Y L V I A  G A N I', 'Gina Diaz', 'Twinkle Mukherjee', '', 'ADELA | MBAMIA + LA', 'Whoa, wait. Walmart?', ' Angelina & Styles ', 'Allison Rose', 'Georgia Harbridge', 'Jamie Greenberg', \"The World's Strongest Man\", 'Diane Michiko', 'Ellie Thumann', 'ÀóÀèÀã Marla Catherine ÀäÀéÀó', ' zo√´ isabella poetry', 'Rebekah Steen', 'sabrina ‚Ä¢ explorer  Venice', 'L E X ‚Ä¢ W E I N S T E I N', 'Rachel Broas', 'German Surfergirl France', 'Camilla Cabral', 'Sandra Pinatto ', 'Loja F√≠sica RR Fashion', 'Joan Blackbird', 'My Nguyen', 'Andrew East', 'Mayla Ara√∫jo', 'Sonia Lorenzini ', 'Sofia Dalle Rive', 'Pixie Lott', 'LUCY‚Ä¢PUG', 'Giorgia Caldarulo', 'Francesca Monte', '  ARIADNA TAPIA', 'Tia Lineker', 'Maria Elena', ' n e f e l i b a t a', 'Fearne', 'Poppy Deyes', 'L U F Y ', 'Haley Wight', 'Douglas Booth', 'Gaelle Garcia Diaz', 'thewhitmore', 'aka BeautybyJJ', 'Helen Anderson', 'JUST YENTL', 'Hobbie Stuart', 'Sublinhando por Patricia Leda', ' vanillestilettos ', 'DIESEL MINNIE', ' A L E K T R A *‚Å∫', '8passengers', 'Bianca Cortez ', 'Missy Ulmer | Sapphire Diaries', 'E M I L Y  (Hagood) J O N E S', 'Gladys, Blogger', 'sally kim | content creator', '  A N N E  W R I G H T ', '‚Ü™Ash and Em‚Ü©', 'C a r o l i n e', 'Kristina', 'A I M E E', 'Kasandra Cortigiano', 'Pattie C.Orange County, CA', 'Jenny Bess  DIY Fashion', 'rodrigofaro', 'Teala Dunn', 'Peter Andre', 'Kylee Renee', 'ashlyn  white after labor day', 'TRAVEL COUPLE Scott+Collette', 'Chelsea Watson', 'Shelby Revis', 'Jennifer H', 'TamaraCamera', 'Shannon Jenkins', 'Ashley Solberg', 'Graffagnini Management Agency', 'Stefanie McKim', 'Audrey Stowe', 'Lifestyle Blogger || Amanda', 'Vanessa Rose Tilley', 'LOLA', 'Claire ', 'CHLO√â |FASHION BLOGGER', 'MADDY CORBIN', 'CAYLETH VIVAS', 'C√©line ', 'Taima', 'Kayla Crosby ', 'Brittney Mahler', 'Tiffany  - Beauty Influencer', 'Annie Cho', 'Hi y‚Äôall, I‚Äôm Brandy G!', 'Mandy']\n"
     ]
    }
   ],
   "source": [
    "#remove emoji symbols from their names\n",
    "emoji_pattern  = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "def remove_emoji(input_string):\n",
    "    return emoji_pattern.sub(r'', input_string ) # No emoji\n",
    "\n",
    "no_emoji =  [remove_emoji(i) if str(i) != 'nan' else i for i in influencer_names ]\n",
    "\n",
    "print(no_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorena Improta', 'Gabi Brandt', 'CREME PARA ESTRIAS', 'Priscila Sim√µes', 'MORGANA SANTANA']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning: invalid escape sequence \\,\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\,\n",
      "/tmp/ipykernel_8287/235454804.py:4: DeprecationWarning: invalid escape sequence \\,\n",
      "  punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~‚Ä¢'''\n"
     ]
    }
   ],
   "source": [
    "#clean up punctuation from list of influencer names\n",
    "\n",
    "def remove_punc(string):\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~‚Ä¢'''\n",
    "    for ele in string:  \n",
    "        if ele in punc:  \n",
    "            string = string.replace(ele, \" \") \n",
    "    return string\n",
    " \n",
    "no_punc_name = [remove_punc(i) if str(i) != 'nan' else i for i in no_emoji]\n",
    "no_punc_name = [i.strip() if str(i) != 'nan' else i  for i in no_punc_name]\n",
    "\n",
    "print(no_punc_name[:5]) # cleaned list and spaces stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning: invalid escape sequence \\(\n",
      "<>:1: DeprecationWarning: invalid escape sequence \\(\n",
      "/tmp/ipykernel_8287/4048533316.py:1: DeprecationWarning: invalid escape sequence \\(\n",
      "  clean_parens_text = [re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x)if str(x) != 'nan' else x for x in no_punc_name ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Lorena Improta',\n",
       " 'Gabi Brandt',\n",
       " 'CREME PARA ESTRIAS',\n",
       " 'Priscila Sim√µes',\n",
       " 'MORGANA SANTANA']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_parens_text = [re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x)if str(x) != 'nan' else x for x in no_punc_name ]\n",
    "\n",
    "clean_parens_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorena Improta', 'Gabi Brandt', 'CREME PARA ESTRIAS', 'Priscila Sim√µes', 'MORGANA SANTANA']\n"
     ]
    }
   ],
   "source": [
    "#clean up prefix titles\n",
    "titles = (\"MR\",\"DR\",\"MRS\",\"PROF\",\"MS\")\n",
    "ptrn = re.compile(fr\"^({'|'.join(titles)})\\.?\\s+\", flags=re.I)\n",
    "clean_names = [ptrn.sub(\"\", i) if str(i) != 'nan' else i for i in clean_parens_text]\n",
    "print(clean_names[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape Famous person attributes data if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8287/2845466619.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)\n"
     ]
    }
   ],
   "source": [
    "name_list = []\n",
    "day_list = []\n",
    "year_list = []\n",
    "age_list = []\n",
    "birth_list = []\n",
    "\n",
    "\n",
    "options = Options()\n",
    "DRIVER_PATH = '/Users/squach/Downloads/chromedriver'\n",
    "driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)\n",
    "\n",
    "\n",
    "# options.headless = True\n",
    "options.add_argument(\"--window-size=1920,1200\")\n",
    "action = webdriver.ActionChains(driver)\n",
    "\n",
    "xpath_name = '/html/body/div[1]/div[1]/div/div/div[2]/div/div/div[1]/div/div[1]/h1'\n",
    "xpath_date =  '/html/body/div[1]/div[1]/div/div/div[2]/div/div/div[2]/div/div[1]/div/div[1]/div/a[1]'\n",
    "xpath_year = '/html/body/div[1]/div[1]/div/div/div[2]/div/div/div[2]/div/div[1]/div/div[1]/div/a[2]'\n",
    "xpath_age = '/html/body/div[1]/div[1]/div/div/div[2]/div/div/div[2]/div/div[1]/div/div[3]/div/a'\n",
    "birthplace_path = '/html/body/div[1]/div[1]/div/div/div[2]/div/div/div[2]/div/div[1]/div/div[2]/div'\n",
    "\n",
    "for names in clean_names:\n",
    "    if str(names) != 'nan' and names.strip() != '':\n",
    "        driver.get(\"https:www.famousbirthdays.com\")\n",
    "\n",
    "        inputElement = driver.find_element(\"id\",\"main-search\")\n",
    "        inputElement.send_keys(names)\n",
    "\n",
    "        #print(\"looking at this name\", names)\n",
    "\n",
    "        inputElement.send_keys(Keys.ENTER)\n",
    "\n",
    "        #wait 4.5 seconds so the site doesn't ask to confirm that i'm not a bot\n",
    "        time.sleep(4.5) \n",
    "\n",
    "        try:\n",
    "            name = driver.find_element(\"xpath\",xpath_name).text\n",
    "            date = driver.find_element(\"xpath\",xpath_date).text\n",
    "            year = driver.find_element(\"xpath\",xpath_year).text\n",
    "            age = driver.find_element(\"xpath\",xpath_age).text\n",
    "            birthplace = driver.find_element(\"xpath\",birthplace_path).text\n",
    "\n",
    "            name_list.append(name)\n",
    "            day_list.append(date)\n",
    "            year_list.append(year)\n",
    "            age_list.append(age)\n",
    "            birth_list.append(birthplace)\n",
    "        except:\n",
    "            name_list.append(names)\n",
    "            day_list.append('n/a')\n",
    "            year_list.append('n/a')\n",
    "            age_list.append('n/a')\n",
    "            birth_list.append('n/a')\n",
    "    else:\n",
    "        name_list.append(names)\n",
    "        day_list.append('n/a')\n",
    "        year_list.append('n/a')\n",
    "        age_list.append('n/a')\n",
    "        birth_list.append('n/a')\n",
    "        \n",
    "        \n",
    "        driver.back()\n",
    "    \n",
    "    \n",
    "    driver.back()\n",
    "\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil', 'Sao Jose do Rio Preto, Brazil', 'n/a', 'Brazil', 'Brazil', 'n/a', 'Plymouth, England', 'England', 'England', 'n/a']\n"
     ]
    }
   ],
   "source": [
    "# it was easier to grab the Xpath to all the information under the Birthplace div class an just clean it up\n",
    "# afterwards. Some only had the country listed, and for the City, States located separately and end up \n",
    "# combining it afterwards. \n",
    "\n",
    "birth_list_clean = [s.replace('BIRTHPLACE\\n', '') for s in birth_list]\n",
    "print(birth_list_clean[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer_about_df = pd.DataFrame({'Unique_Influencer_Name':influencer_names})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influencer_about_df\n",
    "\n",
    "influencer_about_df['Clean_Name'] = name_list\n",
    "influencer_about_df['Birthdate'] = day_list\n",
    "influencer_about_df['Birth_Year'] = year_list\n",
    "influencer_about_df['Age'] = age_list\n",
    "influencer_about_df['Birthplace'] = birth_list_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencer_about_df.to_csv(\"Influencer_Info_Scrape.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_Influencer_Name</th>\n",
       "      <th>Clean_Name</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Birth_Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Birthplace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>September 1</td>\n",
       "      <td>1993</td>\n",
       "      <td>29 years old</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>January 15</td>\n",
       "      <td>1996</td>\n",
       "      <td>26 years old</td>\n",
       "      <td>Sao Jose do Rio Preto, Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>September 18</td>\n",
       "      <td>1992</td>\n",
       "      <td>30 years old</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MORGANA SANTANA</td>\n",
       "      <td>Morgana Santana</td>\n",
       "      <td>June 9</td>\n",
       "      <td>1998</td>\n",
       "      <td>24 years old</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Brittney Mahler</td>\n",
       "      <td>Brittney Mahler</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Tiffany üåπ - Beauty Influencer</td>\n",
       "      <td>Tiffany    Beauty Influencer</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Annie Cho</td>\n",
       "      <td>Annie Cho</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Hi y‚Äôall, I‚Äôm Brandy G!</td>\n",
       "      <td>Hi y‚Äôall  I‚Äôm Brandy G</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Mandy</td>\n",
       "      <td>Mandy</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unique_Influencer_Name                    Clean_Name  \\\n",
       "0                   Lorena Improta                Lorena Improta   \n",
       "1                      Gabi Brandt                   Gabi Brandt   \n",
       "2               CREME PARA ESTRIAS            CREME PARA ESTRIAS   \n",
       "3                  Priscila Sim√µes               Priscila Sim√µes   \n",
       "4                  MORGANA SANTANA               Morgana Santana   \n",
       "..                             ...                           ...   \n",
       "274                Brittney Mahler               Brittney Mahler   \n",
       "275  Tiffany üåπ - Beauty Influencer  Tiffany    Beauty Influencer   \n",
       "276                      Annie Cho                     Annie Cho   \n",
       "277        Hi y‚Äôall, I‚Äôm Brandy G!        Hi y‚Äôall  I‚Äôm Brandy G   \n",
       "278                          Mandy                         Mandy   \n",
       "\n",
       "        Birthdate Birth_Year           Age                     Birthplace  \n",
       "0     September 1       1993  29 years old                         Brazil  \n",
       "1      January 15       1996  26 years old  Sao Jose do Rio Preto, Brazil  \n",
       "2             n/a        n/a           n/a                            n/a  \n",
       "3    September 18       1992  30 years old                         Brazil  \n",
       "4          June 9       1998  24 years old                         Brazil  \n",
       "..            ...        ...           ...                            ...  \n",
       "274           n/a        n/a           n/a                            n/a  \n",
       "275           n/a        n/a           n/a                            n/a  \n",
       "276           n/a        n/a           n/a                            n/a  \n",
       "277           n/a        n/a           n/a                            n/a  \n",
       "278           n/a        n/a           n/a                            n/a  \n",
       "\n",
       "[279 rows x 6 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influencer_about_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influencerID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Influencer_Name</th>\n",
       "      <th>Number_Of_Followers</th>\n",
       "      <th>Number_of_Followees</th>\n",
       "      <th>Number_Of_Posts</th>\n",
       "      <th>Influencer_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378335</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>5074442.0</td>\n",
       "      <td>1966</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51458</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>1782185.0</td>\n",
       "      <td>302</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372578</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>555818.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>Lifestyle Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56832</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>389510.0</td>\n",
       "      <td>750</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4635</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>MORGANA SANTANA</td>\n",
       "      <td>256163.0</td>\n",
       "      <td>509</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>175642</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Brittney Mahler</td>\n",
       "      <td>21308.0</td>\n",
       "      <td>2343</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>7392</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Tiffany üåπ - Beauty Influencer</td>\n",
       "      <td>19260.0</td>\n",
       "      <td>6305</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>376151</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Annie Cho</td>\n",
       "      <td>16072.0</td>\n",
       "      <td>1825</td>\n",
       "      <td>531.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>50475</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Hi y‚Äôall, I‚Äôm Brandy G!</td>\n",
       "      <td>15444.0</td>\n",
       "      <td>1565</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>51760</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Mandy</td>\n",
       "      <td>15300.0</td>\n",
       "      <td>4704</td>\n",
       "      <td>386.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     influencerID       LABEL                Influencer_Name  \\\n",
       "0          378335  Influencer                 Lorena Improta   \n",
       "1           51458  Influencer                    Gabi Brandt   \n",
       "2          372578  Influencer             CREME PARA ESTRIAS   \n",
       "3           56832  Influencer                Priscila Sim√µes   \n",
       "4            4635  Influencer                MORGANA SANTANA   \n",
       "..            ...         ...                            ...   \n",
       "274        175642  Influencer                Brittney Mahler   \n",
       "275          7392  Influencer  Tiffany üåπ - Beauty Influencer   \n",
       "276        376151  Influencer                      Annie Cho   \n",
       "277         50475  Influencer        Hi y‚Äôall, I‚Äôm Brandy G!   \n",
       "278         51760  Influencer                          Mandy   \n",
       "\n",
       "     Number_Of_Followers  Number_of_Followees  Number_Of_Posts  \\\n",
       "0              5074442.0                 1966           5127.0   \n",
       "1              1782185.0                  302           1803.0   \n",
       "2               555818.0                 1951           2045.0   \n",
       "3               389510.0                  750           1337.0   \n",
       "4               256163.0                  509           2029.0   \n",
       "..                   ...                  ...              ...   \n",
       "274              21308.0                 2343            229.0   \n",
       "275              19260.0                 6305            184.0   \n",
       "276              16072.0                 1825            531.0   \n",
       "277              15444.0                 1565           1088.0   \n",
       "278              15300.0                 4704            386.0   \n",
       "\n",
       "        Influencer_Category  \n",
       "0    Creators & Celebrities  \n",
       "1    Creators & Celebrities  \n",
       "2        Lifestyle Services  \n",
       "3    Creators & Celebrities  \n",
       "4    Creators & Celebrities  \n",
       "..                      ...  \n",
       "274  Creators & Celebrities  \n",
       "275  Creators & Celebrities  \n",
       "276  Creators & Celebrities  \n",
       "277  Creators & Celebrities  \n",
       "278  Creators & Celebrities  \n",
       "\n",
       "[279 rows x 7 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influNodesDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>influencerID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>Influencer_Name</th>\n",
       "      <th>Number_Of_Followers</th>\n",
       "      <th>Number_of_Followees</th>\n",
       "      <th>Number_Of_Posts</th>\n",
       "      <th>Influencer_Category</th>\n",
       "      <th>Unique_Influencer_Name</th>\n",
       "      <th>Clean_Name</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Birth_Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Birthplace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>378335</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>5074442.0</td>\n",
       "      <td>1966</td>\n",
       "      <td>5127.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>Lorena Improta</td>\n",
       "      <td>September 1</td>\n",
       "      <td>1993</td>\n",
       "      <td>29 years old</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51458</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>1782185.0</td>\n",
       "      <td>302</td>\n",
       "      <td>1803.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>Gabi Brandt</td>\n",
       "      <td>January 15</td>\n",
       "      <td>1996</td>\n",
       "      <td>26 years old</td>\n",
       "      <td>Sao Jose do Rio Preto, Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>372578</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>555818.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>Lifestyle Services</td>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>CREME PARA ESTRIAS</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56832</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>389510.0</td>\n",
       "      <td>750</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>Priscila Sim√µes</td>\n",
       "      <td>September 18</td>\n",
       "      <td>1992</td>\n",
       "      <td>30 years old</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4635</td>\n",
       "      <td>Influencer</td>\n",
       "      <td>MORGANA SANTANA</td>\n",
       "      <td>256163.0</td>\n",
       "      <td>509</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>Creators &amp; Celebrities</td>\n",
       "      <td>MORGANA SANTANA</td>\n",
       "      <td>Morgana Santana</td>\n",
       "      <td>June 9</td>\n",
       "      <td>1998</td>\n",
       "      <td>24 years old</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   influencerID       LABEL     Influencer_Name  Number_Of_Followers  \\\n",
       "0        378335  Influencer      Lorena Improta            5074442.0   \n",
       "1         51458  Influencer         Gabi Brandt            1782185.0   \n",
       "2        372578  Influencer  CREME PARA ESTRIAS             555818.0   \n",
       "3         56832  Influencer     Priscila Sim√µes             389510.0   \n",
       "4          4635  Influencer     MORGANA SANTANA             256163.0   \n",
       "\n",
       "   Number_of_Followees  Number_Of_Posts     Influencer_Category  \\\n",
       "0                 1966           5127.0  Creators & Celebrities   \n",
       "1                  302           1803.0  Creators & Celebrities   \n",
       "2                 1951           2045.0      Lifestyle Services   \n",
       "3                  750           1337.0  Creators & Celebrities   \n",
       "4                  509           2029.0  Creators & Celebrities   \n",
       "\n",
       "  Unique_Influencer_Name          Clean_Name     Birthdate Birth_Year  \\\n",
       "0         Lorena Improta      Lorena Improta   September 1       1993   \n",
       "1            Gabi Brandt         Gabi Brandt    January 15       1996   \n",
       "2     CREME PARA ESTRIAS  CREME PARA ESTRIAS           n/a        n/a   \n",
       "3        Priscila Sim√µes     Priscila Sim√µes  September 18       1992   \n",
       "4        MORGANA SANTANA     Morgana Santana        June 9       1998   \n",
       "\n",
       "            Age                     Birthplace  \n",
       "0  29 years old                         Brazil  \n",
       "1  26 years old  Sao Jose do Rio Preto, Brazil  \n",
       "2           n/a                            n/a  \n",
       "3  30 years old                         Brazil  \n",
       "4  24 years old                         Brazil  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influNodesFinalDf = pd.merge(influNodesDf, influencer_about_df, how='inner', \\\n",
    "                             left_on = 'Influencer_Name', right_on = 'Unique_Influencer_Name')\n",
    "influNodesFinalDf\n",
    "influNodesFinalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influNodesDf.to_csv(\"InfluencerNodes.csv\", index=False)\n",
    "postNodesDf.to_csv(\"PostNodes.csv\", index=False)\n",
    "brandNodeDf.to_csv(\"BrandNodes.csv\", index=False)\n",
    "edge_relinfltopost.to_csv(\"Edges_Infl.csv\", index=False)\n",
    "edge_brandtopost.to_csv(\"Edges_Brand.csv\", index=False)\n",
    "#relationList.to_csv(\"files/relationList.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
